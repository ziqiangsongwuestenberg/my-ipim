# ===============================
# Example application properties
# Copy this file to:
#   application.properties
# and adjust values for your local environment
# ===============================

# DB
spring.datasource.url=jdbc:postgresql://localhost:5432/devdb
spring.datasource.username=postgres
spring.datasource.password=postgres
spring.datasource.driver-class-name=org.postgresql.Driver

# JPA / Hibernate
spring.jpa.hibernate.ddl-auto=update
spring.jpa.show-sql=true
spring.jpa.open-in-view=false

# Server
server.port=8081

mypim.export.page-size=500
mypim.export.include-deleted=false
mypim.export.attribute-whitelist=vin,available_to,length_mm
mypim.export.price-whitelist=LIST_PRICE,SALE_PRICE
mypim.export.statuses.status1[0]=1
mypim.export.statuses.status1[1]=2

# Log
# logging.level.com.song.my_pim=INFO
logging.level.com.song.my_pim.service.exportjob=DEBUG

# Flyway
spring.flyway.enabled=false

mypim.export.file-name=articles-export.xml

#upload file to s3 bucket
aws.access-key-id=dummy
aws.secret-access-key=dummy
mypim.s3.bucket=my-ipim-exports
mypim.s3.region=eu-north-1
mypim.s3.prefix=exports/articles

# Resilience4j for S3 Upload
# TimeLimiter: timeout control for upload
resilience4j.timelimiter.instances.s3Upload.timeout-duration=20s
resilience4j.timelimiter.instances.s3Upload.cancel-running-future=true
# Retry: 4 attempts (1 initial + 3 retries), exponential backoff + jitter
resilience4j.retry.instances.s3Upload.max-attempts=4
resilience4j.retry.instances.s3Upload.wait-duration=500ms
resilience4j.retry.instances.s3Upload.enable-exponential-backoff=true
resilience4j.retry.instances.s3Upload.exponential-backoff-multiplier=2
resilience4j.retry.instances.s3Upload.enable-randomized-wait=true
resilience4j.retry.instances.s3Upload.randomized-wait-factor=0.4
# CircuitBreaker: 50-call window, start evaluating after 20 calls, open when failure rate reaches 50%
resilience4j.circuitbreaker.instances.s3Upload.sliding-window-type=COUNT_BASED
resilience4j.circuitbreaker.instances.s3Upload.sliding-window-size=50
resilience4j.circuitbreaker.instances.s3Upload.minimum-number-of-calls=20
resilience4j.circuitbreaker.instances.s3Upload.failure-rate-threshold=50
resilience4j.circuitbreaker.instances.s3Upload.wait-duration-in-open-state=30s
resilience4j.circuitbreaker.instances.s3Upload.permitted-number-of-calls-in-half-open-state=5
# Slow calls: any call taking longer than 10s is considered slow (also affects circuit breaker decisions)
resilience4j.circuitbreaker.instances.s3Upload.slow-call-duration-threshold=10s
resilience4j.circuitbreaker.instances.s3Upload.slow-call-rate-threshold=50
# Bulkhead (optional but recommended): limit concurrent uploads to avoid exhausting threads/connections
resilience4j.bulkhead.instances.s3Upload.max-concurrent-calls=10
resilience4j.bulkhead.instances.s3Upload.max-wait-duration=0
# Fault Tolerance: simulate network/S3 glitches (only for S3Upload testing)
my-pim.fault.s3.enabled=false
my-pim.fault.s3.fail-first-n=1

# payload
mypim.export.payload.base-dir=/tmp/myipim-payload
mypim.export.payload.file-prefix=articles-export

# export chunk count
mypim.export.chunk-parts=4
# thread pool
mypim.export.thread-pool.core-pool-size=4
mypim.export.thread-pool.max-pool-size=8
mypim.export.thread-pool.queue-capacity=200

# prometheus
management.endpoints.web.exposure.include=health,info,prometheus,metrics
management.endpoint.health.probes.enabled=true